{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 NASA\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Rice mapping in Bhutan with U-Net using high resolution satellite imagery\n",
        "\n",
        "### This notebook shows an example of counting the sample size from the `tfrecords`\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/SERVIR/servir-aces/blob/main/notebooks/count_sample_size.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/SERVIR/servir-aces/blob/main/notebooks/count_sample_size.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "</table>\n",
        "</br>\n",
        "</br>\n",
        "</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zk3R20LkKet"
      },
      "source": [
        "This notebook is also available in this github repo: https://github.com/SERVIR/servir-aces. Navigate to the `notebooks` folder."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment"
      ],
      "metadata": {
        "id": "EuQkhSxRmiIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install servir-aces"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuDztFucmhpB",
        "outputId": "d0264259-b3e9-4550-8e84-3c457c282473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting servir-aces\n",
            "  Downloading servir_aces-0.0.9-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from servir-aces) (1.25.2)\n",
            "Requirement already satisfied: tensorflow>=2.9.3 in /usr/local/lib/python3.10/dist-packages (from servir-aces) (2.15.0)\n",
            "Collecting apache-beam>=2.38.0 (from servir-aces)\n",
            "  Downloading apache_beam-2.55.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: earthengine-api in /usr/local/lib/python3.10/dist-packages (from servir-aces) (0.1.397)\n",
            "Collecting python-dotenv>=1.0.0 (from servir-aces)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from servir-aces) (3.7.1)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (1.62.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (0.22.0)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (3.0.3)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (24.0)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading pymongo-4.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (676 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (2023.4)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (2023.12.25)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (4.11.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<15.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam>=2.38.0->servir-aces) (0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (0.36.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (2.15.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (2.8.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (0.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (3.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.3->servir-aces) (0.43.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->earthengine-api->servir-aces) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->earthengine-api->servir-aces) (4.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api->servir-aces) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api->servir-aces) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api->servir-aces) (4.9)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam>=2.38.0->servir-aces) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam>=2.38.0->servir-aces) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam>=2.38.0->servir-aces) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam>=2.38.0->servir-aces) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam>=2.38.0->servir-aces) (0.18.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam>=2.38.0->servir-aces)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam>=2.38.0->servir-aces) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam>=2.38.0->servir-aces) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam>=2.38.0->servir-aces) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam>=2.38.0->servir-aces) (2024.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (3.0.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->earthengine-api->servir-aces) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->earthengine-api->servir-aces) (2.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api->servir-aces) (1.63.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->earthengine-api->servir-aces) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api->servir-aces) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (2.1.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (3.2.2)\n",
            "Building wheels for collected packages: crcmod, dill, hdfs, pyjsparser, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=0581a0c7d8dd62c82860d31e9d6d6763e33bd79a7e999a6fec7575b21631e393\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=12d7081df0b4382a7eecdfad3bbb1963bca50ece97506c0d00175be9382b2610\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=9227978eb685ff1e48d3fe0601997a7c9d72ddb6b324e8e1906d8c59b16cf612\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=9eda250c49511a1e39cade04dfe7b2f069077af9ae9c5d10c99c2d394fac17d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=f74a5bc32068aa4d946f8e29a4184368ed792e32d41a61fe8d6952db3ef388cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs pyjsparser docopt\n",
            "Installing collected packages: pyjsparser, docopt, crcmod, zstandard, python-dotenv, orjson, objsize, js2py, fasteners, fastavro, dnspython, dill, pymongo, hdfs, apache-beam, servir-aces\n",
            "Successfully installed apache-beam-2.55.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 fastavro-1.9.4 fasteners-0.19 hdfs-2.7.3 js2py-0.74 objsize-0.7.0 orjson-3.10.1 pyjsparser-2.7.1 pymongo-4.6.3 python-dotenv-1.0.1 servir-aces-0.0.9 zstandard-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SERVIR/servir-aces"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PvoP9Sgqz4e",
        "outputId": "520bf5dd-3e72-46f6-b280-5120837888dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'servir-aces'...\n",
            "remote: Enumerating objects: 671, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 671 (delta 42), reused 69 (delta 38), pack-reused 572\u001b[K\n",
            "Receiving objects: 100% (671/671), 2.33 MiB | 4.83 MiB/s, done.\n",
            "Resolving deltas: 100% (419/419), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the repo is downloaded. We will create an environment file file to place point to our training data and customize parameters for the model. To do this, we make a copy of the `.env.example` file provided.\n",
        "\n",
        "Under the hood, all the configuration provided via the environment file are parsed as a config object and can be accessed programatically.\n",
        "\n",
        "Note current version does not expose all the model intracacies through the environment file but future version may include those depending on the need."
      ],
      "metadata": {
        "id": "RukLD6eeq7Fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp servir-aces/.env.example servir-aces/config.env"
      ],
      "metadata": {
        "id": "jpnfjXRYsYMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup config file variables"
      ],
      "metadata": {
        "id": "NOoH9ZJq0g80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, now we have the `config.env` file, we will use this to provide our environments and parameters.\n",
        "\n",
        "Note there are several parameters that can be changed. Let's start by changing the BASEDIR as below.\n",
        "\n",
        "```\n",
        "BASEDIR = \"/content/\"\n",
        "```"
      ],
      "metadata": {
        "id": "ooFqBUY3gS5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will download data for this chapter. We will use `datasets` dir to download the data. Let's go ahead and create that."
      ],
      "metadata": {
        "id": "Oqyc1EHFhC9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/datasets"
      ],
      "metadata": {
        "id": "RnkHrSYThBZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go ahead and download the datasets for which we need to calculate the number of samples. They can be found at the google cloud storage and we will use `gsutil` to get the dataset in our workspace. Each folder/ dataset has `training`, `testing`, and `validation` subdirectory. Let's start by downloading these datasets in our workspace."
      ],
      "metadata": {
        "id": "hyyTqvnahc2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil -m cp -r gs://dl-book/chapter-1/* /content/datasets"
      ],
      "metadata": {
        "id": "6Ft4VMolhjgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e15debe-225a-40a5-b035-2c195af578e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://dl-book/chapter-1/.DS_Store...\n",
            "Copying gs://dl-book/chapter-1/dnn_planet_wo_indices/testing/testing.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/  6.0 KiB]                                                \r/ [0 files][    0.0 B/ 58.1 KiB]                                                \rCopying gs://dl-book/chapter-1/dnn_planet_wo_indices/training/training.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/410.4 KiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100000.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/ 50.8 MiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100003.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/ 96.7 MiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100002.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/143.8 MiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100005.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/145.4 MiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100001.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/191.1 MiB]                                                \rCopying gs://dl-book/chapter-1/dnn_planet_wo_indices/validation/validation.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/images/image_202100004.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/images/image_2021mixer.json...\n",
            "Copying gs://dl-book/chapter-1/prediction/prediction_dnn_v1.TFRecord...\n",
            "Copying gs://dl-book/chapter-1/prediction/prediction_unet_v1.TFRecord...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00000-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00001-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00002-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00003-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00004-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00005-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00006-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00007-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00008-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00009-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00010-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00011-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00012-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00013-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00014-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00015-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00016-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00017-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00018-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00019-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00020-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00021-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00022-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00023-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00024-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00025-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00026-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00027-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00028-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00029-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00030-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00031-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00032-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00033-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00034-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00035-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00036-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00037-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00000-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00001-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00002-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00003-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00004-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00005-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00006-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00007-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00008-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00009-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00010-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00011-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00012-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00013-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00014-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00015-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00016-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00017-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00018-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00019-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00020-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00021-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00022-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00023-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00024-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00025-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00026-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00027-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00028-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00029-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00030-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00031-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00032-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00033-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00034-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00035-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00036-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00037-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00000-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00001-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00002-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00003-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00004-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00005-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00006-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00007-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00008-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00009-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00010-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00011-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00012-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00013-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00014-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00015-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00016-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00017-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00018-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00019-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00020-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00021-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00022-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00023-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00024-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00025-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00026-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00027-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00028-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00029-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00030-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00031-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00032-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00035-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00033-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00034-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00036-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00037-of-00038.tfrecord.gz...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the `unet_256x256_planet_wo_indices` dataset inside the `dataset` folder for this exercise. Let's go ahead and change our DATADIR in the `config.env` file as below.\n",
        "\n",
        "```\n",
        "DATADIR = \"datasets/unet_256x256_planet_wo_indices\"\n",
        "```"
      ],
      "metadata": {
        "id": "Orc9Qcb3shcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These datasets have RGBN from Planetscope mosiac. Since we are trying to map the rice fields, we use growing season and pre-growing season information. Thus, we have 8 optical bands, namely `red_before`, `green_before`, `blue_before`, `nir_before`, `red_during`, `green_during`, `blue_during`, and  `nir_during`. In adidition, you can use `USE_ELEVATION` and `USE_S1` config to include the topographic and radar information. Since currently we are not including these, so we won't be settting these config values. Similarly, these datasets are tiled to 256x256 pixels, so let's also change that.\n",
        "\n",
        "```\n",
        "# For model training, USE_ELEVATION extends FEATURES with \"elevation\" & \"slope\"\n",
        "# USE_S1 extends FEATURES with \"vv_asc_before\", \"vh_asc_before\", \"vv_asc_during\", \"vh_asc_during\",\n",
        "# \"vv_desc_before\", \"vh_desc_before\", \"vv_desc_during\", \"vh_desc_during\"\n",
        "# In case these are not useful and you have other bands in your training data, you can do set\n",
        "# USE_ELEVATION and USE_S1 to False and update FEATURES to include needed bands\n",
        "USE_ELEVATION = False\n",
        "USE_S1 = False\n",
        "\n",
        "PATCH_SHAPE = (256, 256)\n",
        "```"
      ],
      "metadata": {
        "id": "CEDUshfUi1OY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to calculate the size of the traiing, testing and validation dataset. For this, we know our size before hand. But let's use `aces` useful functionality to calculate this.\n",
        "\n",
        "```\n",
        "# Sizes of the training and evaluation datasets.\n",
        "TRAIN_SIZE = 8531\n",
        "TEST_SIZE = 1222\n",
        "VAL_SIZE = 2404\n",
        "```"
      ],
      "metadata": {
        "id": "p6NF86anh-pS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update the config file programtically"
      ],
      "metadata": {
        "id": "NfPDbBLV0lsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make a dictionary so we can change these config settings programatically."
      ],
      "metadata": {
        "id": "JNPTVh3b0ni-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASEDIR = \"/content/\" # @param {type:\"string\"}\n",
        "DATADIR = \"datasets/unet_256x256_planet_wo_indices\" # @param {type:\"string\"}\n",
        "\n",
        "USE_ELEVATION = \"False\" # @param {type:\"string\"}\n",
        "USE_S1 = \"False\" # @param {type:\"string\"}\n",
        "PATCH_SHAPE = \"(256, 256)\" # @param {type:\"string\"}\n",
        "\n",
        "BATCH_SIZE = \"32\" # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "_siYzZ0c0ptu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_settings = {\n",
        "    \"BASEDIR\" : BASEDIR,\n",
        "    \"DATADIR\": DATADIR,\n",
        "    \"USE_ELEVATION\": USE_ELEVATION,\n",
        "    \"USE_S1\": USE_S1,\n",
        "    \"PATCH_SHAPE\": PATCH_SHAPE,\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "}\n"
      ],
      "metadata": {
        "id": "qQrcO_Jr2qxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dotenv\n",
        "\n",
        "config_file = \"servir-aces/config.env\"\n",
        "\n",
        "for config_key in config_settings:\n",
        "    dotenv.set_key(dotenv_path=config_file,\n",
        "                   key_to_set=config_key,\n",
        "                   value_to_set=config_settings[config_key]\n",
        "                   )\n"
      ],
      "metadata": {
        "id": "6HD5aB2D2wfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load config file variables"
      ],
      "metadata": {
        "id": "lRMRDBh82ziD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aces import Config, DataProcessor"
      ],
      "metadata": {
        "id": "AWToBRVmqkok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_file = \"/content/servir-aces/config.env\"\n",
        "config = Config(config_file, override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0zB2echioW0",
        "outputId": "6e9b5cef-b00d-40aa-aa31-d91c34694c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASEDIR: /content\n",
            "DATADIR: /content/datasets/unet_256x256_planet_wo_indices\n",
            "using features: ['red_before', 'green_before', 'blue_before', 'nir_before', 'red_during', 'green_during', 'blue_during', 'nir_during']\n",
            "using labels: ['class']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the config in the `config.env` is now available via the config instance. Let's check few of them here."
      ],
      "metadata": {
        "id": "yPKv3W5crsf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config.TRAINING_DIR, config.BATCH_SIZE, config.FEATURES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dgS1btomEqO",
        "outputId": "dd0a309d-bd6b-4e19-d836-3971018a7936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/content/datasets/unet_256x256_planet_wo_indices/training'),\n",
              " 32,\n",
              " ['red_before',\n",
              "  'green_before',\n",
              "  'blue_before',\n",
              "  'nir_before',\n",
              "  'red_during',\n",
              "  'green_during',\n",
              "  'blue_during',\n",
              "  'nir_during'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the number of records"
      ],
      "metadata": {
        "id": "EGbpDtPlf9_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `calculate_n_samples` static function of the `DataProcessor` class to get the number of records for each split. You can provide additional parameters (`PRINT_DATASET`) as well."
      ],
      "metadata": {
        "id": "WYvPo_P5gB1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "additional_config = {\n",
        "    \"PRINT_DATASET\": True\n",
        "}\n",
        "n_training_records, n_testing_records, n_validation_records = DataProcessor.calculate_n_samples(**{**config.__dict__, **additional_config})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9Gm_VSixBz",
        "outputId": "c16febc0-eda4-4ba6-fc7a-9a57e6627ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training\n",
            "inputs: float32 (256, 256, 8)\n",
            "tf.Tensor(\n",
            "[[[0.0533   0.060125 0.033475 ... 0.054225 0.02415  0.337825]\n",
            "  [0.05275  0.059825 0.033125 ... 0.05405  0.022475 0.341325]\n",
            "  [0.06195  0.06465  0.0364   ... 0.05005  0.02265  0.251175]\n",
            "  ...\n",
            "  [0.02165  0.022425 0.0111   ... 0.024725 0.00965  0.144825]\n",
            "  [0.022525 0.023275 0.011775 ... 0.0275   0.010575 0.156375]\n",
            "  [0.0181   0.025125 0.0115   ... 0.0257   0.00965  0.145225]]\n",
            "\n",
            " [[0.04455  0.054675 0.032125 ... 0.04935  0.02175  0.300325]\n",
            "  [0.0435   0.054075 0.0313   ... 0.04645  0.0205   0.292875]\n",
            "  [0.048825 0.057775 0.0327   ... 0.04545  0.020725 0.268675]\n",
            "  ...\n",
            "  [0.0221   0.024925 0.0136   ... 0.025375 0.0117   0.12375 ]\n",
            "  [0.018125 0.0269   0.012975 ... 0.02125  0.009275 0.118775]\n",
            "  [0.020975 0.023875 0.012175 ... 0.023875 0.0129   0.123425]]\n",
            "\n",
            " [[0.0453   0.05215  0.032375 ... 0.0502   0.02265  0.276275]\n",
            "  [0.045575 0.05125  0.032075 ... 0.0467   0.022625 0.267225]\n",
            "  [0.052175 0.055175 0.032475 ... 0.045325 0.021275 0.277025]\n",
            "  ...\n",
            "  [0.0235   0.025725 0.014475 ... 0.02505  0.0115   0.119875]\n",
            "  [0.022    0.024875 0.013725 ... 0.022025 0.011525 0.110175]\n",
            "  [0.0196   0.02435  0.01205  ... 0.02295  0.011125 0.119625]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.02405  0.0374   0.019575 ... 0.0368   0.01665  0.251125]\n",
            "  [0.023175 0.034875 0.018375 ... 0.03475  0.015025 0.24105 ]\n",
            "  [0.0218   0.035325 0.017625 ... 0.0323   0.014275 0.225175]\n",
            "  ...\n",
            "  [0.0937   0.0795   0.0584   ... 0.05475  0.023375 0.36975 ]\n",
            "  [0.088725 0.07665  0.058875 ... 0.061725 0.028975 0.368675]\n",
            "  [0.086475 0.07225  0.0557   ... 0.061525 0.033975 0.36415 ]]\n",
            "\n",
            " [[0.025475 0.037125 0.0198   ... 0.037075 0.016925 0.25905 ]\n",
            "  [0.02335  0.03605  0.018325 ... 0.03365  0.014325 0.229375]\n",
            "  [0.023925 0.03665  0.019075 ... 0.036425 0.015475 0.227175]\n",
            "  ...\n",
            "  [0.081575 0.072725 0.052075 ... 0.0519   0.022    0.33015 ]\n",
            "  [0.092275 0.079675 0.062175 ... 0.059975 0.028025 0.35645 ]\n",
            "  [0.092325 0.07785  0.05815  ... 0.0619   0.033875 0.355125]]\n",
            "\n",
            " [[0.023975 0.037625 0.0196   ... 0.03535  0.013825 0.2419  ]\n",
            "  [0.024875 0.03635  0.0193   ... 0.036525 0.014875 0.22715 ]\n",
            "  [0.02675  0.0385   0.020325 ... 0.0402   0.016775 0.246225]\n",
            "  ...\n",
            "  [0.07685  0.0728   0.051125 ... 0.04735  0.02065  0.30265 ]\n",
            "  [0.086575 0.07755  0.055875 ... 0.055925 0.02605  0.32185 ]\n",
            "  [0.0968   0.080875 0.060825 ... 0.0614   0.0294   0.330175]]], shape=(256, 256, 8), dtype=float32)\n",
            "outputs: float32 (256, 256, 5)\n",
            "tf.Tensor(\n",
            "[[[0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]]], shape=(256, 256, 5), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/aces/data_processor.py:55: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.ignore_errors` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 32s, sys: 10.4 s, total: 3min 43s\n",
            "Wall time: 3min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"no of training records: {n_training_records}\")\n",
        "print(f\"no of testing records: {n_testing_records}\")\n",
        "print(f\"no of validation records: {n_validation_records}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1v6DU2umAzp",
        "outputId": "c494d154-37cf-45ef-d2b3-a4676a5ff8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of training records: 8531\n",
            "no of testing records: 1222\n",
            "no of validation records: 2404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI3DZXi8Po4j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}